{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 98885,
          "databundleVersionId": 11800270,
          "sourceType": "competition"
        }
      ],
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "baseline",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MalakhovDenis/DLS-DL2/blob/main/17.%20%F0%9F%A4%93%D0%94%D0%97-6.%20%D0%94%D0%B5%D1%82%D0%B5%D0%BA%D1%86%D0%B8%D1%8F%20%D1%81%D0%B3%D0%B5%D0%BD%D0%B5%D1%80%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%BD%D1%8B%D1%85%20%D1%82%D0%B5%D0%BA%D1%81%D1%82%D0%BE%D0%B2/17.1.%20%D0%94%D0%BE%D0%BC%D0%B0%D1%88%D0%BD%D0%B5%D0%B5%20%D0%B7%D0%B0%D0%B4%D0%B0%D0%BD%D0%B8%D0%B5.%20%D0%94%D0%B5%D1%82%D0%B5%D0%BA%D1%86%D0%B8%D1%8F%20%D1%81%D0%B3%D0%B5%D0%BD%D0%B5%D1%80%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%BD%D1%8B%D1%85%20%D1%82%D0%B5%D0%BA%D1%81%D1%82%D0%BE%D0%B2/Malakhov%5Bhomework-6%5Dbot-detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "HhOpK1tOu8lk"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "you_are_bot_path = kagglehub.competition_download('you-are-bot')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "sX7Pdvh-u8ln"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, log_loss\n",
        "\n",
        "\n",
        "def load_train_data(data_file: str, labels_file: str):\n",
        "    all_texts = []\n",
        "    all_labels = []\n",
        "\n",
        "    labels_df = pd.read_csv(labels_file)\n",
        "    labels_df = labels_df[labels_df[\"participant_index\"] == 0]\n",
        "    labels_dict = dict(zip(labels_df[\"dialog_id\"], labels_df[\"is_bot\"]))\n",
        "\n",
        "    with open(data_file, \"r\", encoding=\"utf-8\") as f:\n",
        "\n",
        "        data = json.load(f)\n",
        "        for key in data.keys():\n",
        "            messages = data[key]\n",
        "\n",
        "            part_0_texts = [\n",
        "                m[\"text\"] for m in messages if m[\"participant_index\"] == \"0\"\n",
        "            ]\n",
        "            part_1_texts = [\n",
        "                m[\"text\"] for m in messages if m[\"participant_index\"] == \"1\"\n",
        "            ]\n",
        "\n",
        "            part_0_label = int(labels_dict[key])\n",
        "            part_1_label = 1 - part_0_label\n",
        "\n",
        "            text_0 = \" \".join(part_0_texts)\n",
        "            text_1 = \" \".join(part_1_texts)\n",
        "\n",
        "            all_texts.append(text_0)\n",
        "            all_labels.append(part_0_label)\n",
        "\n",
        "            all_texts.append(text_1)\n",
        "            all_labels.append(part_1_label)\n",
        "\n",
        "    df = pd.DataFrame({\"text\": all_texts, \"is_bot\": all_labels})\n",
        "    return df\n",
        "\n",
        "\n",
        "def load_test_data(data_file: str, labels_file: str):\n",
        "    df_info = pd.read_csv(labels_file)\n",
        "\n",
        "    with open(data_file, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    all_texts = []\n",
        "    ids = []\n",
        "\n",
        "    for _, row in df_info.iterrows():\n",
        "        dialog_id = row[\"dialog_id\"]\n",
        "        participant_index = str(row[\"participant_index\"])\n",
        "        messages = data[dialog_id]\n",
        "\n",
        "        texts = [\n",
        "            m[\"text\"] for m in messages if m[\"participant_index\"] == participant_index\n",
        "        ]\n",
        "        combined_text = \" \".join(texts)\n",
        "        all_texts.append(combined_text)\n",
        "        ids.append(row[\"ID\"])\n",
        "\n",
        "    df = pd.DataFrame({\"ID\": ids, \"text\": all_texts})\n",
        "    return df\n",
        "\n",
        "\n",
        "def main():\n",
        "    df = load_train_data(\"you-are-bot/train.json\", \"you-are-bot/ytrain.csv\")\n",
        "    X = df[\"text\"]\n",
        "    y = df[\"is_bot\"]\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    pipe = Pipeline(\n",
        "        [\n",
        "            (\"vectorizer\", TfidfVectorizer()),\n",
        "            (\"model\", LogisticRegression(random_state=42)),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    pipe.fit(X_train, y_train)\n",
        "\n",
        "    val_pred = pipe.predict(X_test)\n",
        "    val_proba = pipe.predict_proba(X_test)\n",
        "    val_acc = accuracy_score(y_test, val_pred)\n",
        "    val_roc = roc_auc_score(y_test, val_proba[:, 1])\n",
        "    val_logloss = log_loss(y_test, val_proba)\n",
        "    print(\"Val Accuracy:\", val_acc)\n",
        "    print(\"Val ROC AUC:\", val_roc)\n",
        "    print(\"Val Log Loss:\", val_logloss)\n",
        "\n",
        "    df_test = load_test_data(\"you-are-bot/test.json\", \"you-are-bot/ytest.csv\")\n",
        "    X_test = df_test[\"text\"]\n",
        "    test_proba = pipe.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    preds_df = pd.DataFrame({\"ID\": df_test[\"ID\"], \"is_bot\": test_proba})\n",
        "    preds_df.to_csv(\"preds.csv\", index=False)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "Sa_rWjE-u8lo"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}